2025-07-10 09:33:19,175 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:33:19,175 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:33:19,175 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:33:19,182 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:33:19,183 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:33:19,183 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:33:19,193 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:33:19,193 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:33:19,197 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:33:19,197 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,300 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:33:19,301 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:33:19,302 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:33:19,302 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,406 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:33:19,406 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:33:19,406 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:33:19,418 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:33:19,418 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,520 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:33:19,521 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:33:19,521 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:33:19,523 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:33:19,523 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,627 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:33:19,627 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:33:19,627 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:33:19,629 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:33:19,629 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,731 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:33:19,731 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:33:19,731 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:33:19,740 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:33:19,742 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,846 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:33:19,846 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:33:19,847 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:33:19,848 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:33:19,848 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:33:19,952 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:33:22,287 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6170daaf-9a33-415a-a208-e04201367339', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:22,287 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:22,288 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:22,295 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114a1f7f0>
2025-07-10 09:33:22,296 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x11037dac0> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:27,314 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:27,314 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:27,332 - DEBUG - openai._base_client - _base_client:1058 - 2 retries left
2025-07-10 09:33:27,338 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.446241 seconds
2025-07-10 09:33:27,790 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6170daaf-9a33-415a-a208-e04201367339', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:27,790 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:27,791 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:27,793 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114a68d00>
2025-07-10 09:33:27,793 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x11037dac0> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:32,795 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:32,796 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:32,797 - DEBUG - openai._base_client - _base_client:1056 - 1 retry left
2025-07-10 09:33:32,797 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.799883 seconds
2025-07-10 09:33:33,605 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6170daaf-9a33-415a-a208-e04201367339', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:33,608 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:33,608 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:33,611 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114a699f0>
2025-07-10 09:33:33,611 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x11037dac0> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:38,612 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:38,613 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:38,614 - DEBUG - openai._base_client - _base_client:989 - Raising timeout error
2025-07-10 09:33:38,875 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2ed1ae72-82ac-4414-bc0a-67f21d48bfe2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:38,875 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:38,876 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:38,879 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114d4d0c0>
2025-07-10 09:33:38,879 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x114a09540> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:43,882 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:43,885 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:43,886 - DEBUG - openai._base_client - _base_client:1058 - 2 retries left
2025-07-10 09:33:43,887 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.407448 seconds
2025-07-10 09:33:44,300 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2ed1ae72-82ac-4414-bc0a-67f21d48bfe2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:44,301 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:44,301 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:44,304 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114d4c3a0>
2025-07-10 09:33:44,304 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x114a09540> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:49,306 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:49,307 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:49,307 - DEBUG - openai._base_client - _base_client:1056 - 1 retry left
2025-07-10 09:33:49,307 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.939814 seconds
2025-07-10 09:33:50,248 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2ed1ae72-82ac-4414-bc0a-67f21d48bfe2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:33:50,249 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:33:50,249 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:33:50,252 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x114d4f9d0>
2025-07-10 09:33:50,253 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x114a09540> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:33:55,254 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:33:55,255 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:33:55,256 - DEBUG - openai._base_client - _base_client:989 - Raising timeout error
2025-07-10 09:33:56,104 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:33:56,107 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:33:56,108 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:33:56,110 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:33:56,128 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:33:56,131 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:33:56,133 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:33:56,138 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:33:56,150 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:33:56,151 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:33:56,151 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:33:56,155 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:35:15,227 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:35:15,228 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:35:15,229 - CRITICAL - root - cli:93 - CLI: 发生意外错误: 'Mock' object is not iterable
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 62, in decompose
    sorted_nodes = list(nx.topological_sort(graph))
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/networkx/algorithms/dag.py", line 309, in topological_sort
    for generation in nx.topological_generations(G):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/networkx/algorithms/dag.py", line 219, in topological_generations
    indegree_map = {v: d for v, d in G.in_degree() if d > 0}
TypeError: 'Mock' object is not iterable
2025-07-10 09:35:15,380 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:35:15,432 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:35:15,457 - CRITICAL - root - cli:93 - CLI: 发生意外错误: 'Mock' object is not iterable
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 51, in decompose
    "graph_nodes": [{"id": node, **graph.nodes[node]} for node in graph.nodes()],
TypeError: 'Mock' object is not iterable
2025-07-10 09:35:15,885 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:35:15,885 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:35:15,885 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:35:15,903 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:35:15,906 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:35:15,907 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:35:15,962 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:35:15,962 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:35:15,991 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:35:15,991 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:35:16,094 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:35:16,115 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:35:16,128 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:35:16,129 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:35:16,232 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:35:16,232 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:35:16,244 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:35:16,275 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:35:16,275 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:35:16,387 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:35:16,388 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:35:16,389 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:35:16,735 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:35:16,736 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:35:16,837 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:35:16,838 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:35:16,838 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:35:16,840 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:35:16,840 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:35:16,941 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:35:16,942 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:35:16,942 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:35:16,945 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:35:16,946 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:35:17,051 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:35:17,051 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:35:17,053 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:35:17,054 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:35:17,054 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:35:17,154 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:35:17,829 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-87a7c139-a57d-488f-b6c5-487783f626e2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:17,829 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:17,830 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:17,840 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111f4e7a0>
2025-07-10 09:35:17,841 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x10f0f5c40> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:22,843 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:22,844 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:22,852 - DEBUG - openai._base_client - _base_client:1058 - 2 retries left
2025-07-10 09:35:22,853 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.376551 seconds
2025-07-10 09:35:23,232 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-87a7c139-a57d-488f-b6c5-487783f626e2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:23,233 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:23,234 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:23,245 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111f4fc70>
2025-07-10 09:35:23,246 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x10f0f5c40> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:28,248 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:28,249 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:28,251 - DEBUG - openai._base_client - _base_client:1056 - 1 retry left
2025-07-10 09:35:28,251 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.899770 seconds
2025-07-10 09:35:29,155 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-87a7c139-a57d-488f-b6c5-487783f626e2', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:29,156 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:29,157 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:29,164 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11620c9a0>
2025-07-10 09:35:29,164 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x10f0f5c40> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:34,166 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:34,166 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:34,167 - DEBUG - openai._base_client - _base_client:989 - Raising timeout error
2025-07-10 09:35:34,576 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54f5560c-ed93-4d32-b7b0-a80e5eac0de5', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:34,576 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:34,577 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:34,584 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1167aa590>
2025-07-10 09:35:34,584 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x1161e7740> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:39,586 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:39,587 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:39,588 - DEBUG - openai._base_client - _base_client:1058 - 2 retries left
2025-07-10 09:35:39,588 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.426889 seconds
2025-07-10 09:35:40,018 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54f5560c-ed93-4d32-b7b0-a80e5eac0de5', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:40,020 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:40,020 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:40,025 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1167a9db0>
2025-07-10 09:35:40,026 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x1161e7740> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:45,028 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:45,031 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:45,032 - DEBUG - openai._base_client - _base_client:1056 - 1 retry left
2025-07-10 09:35:45,032 - INFO - openai._base_client - _base_client:1061 - Retrying request to /chat/completions in 0.762088 seconds
2025-07-10 09:35:45,801 - DEBUG - openai._base_client - _base_client:482 - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-54f5560c-ed93-4d32-b7b0-a80e5eac0de5', 'json_data': {'messages': [{'role': 'system', 'content': '你是一个任务分解助手，请严格按照用户要求输出JSON格式。'}, {'role': 'user', 'content': 'Test prompt'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}
2025-07-10 09:35:45,878 - DEBUG - openai._base_client - _base_client:968 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-07-10 09:35:46,087 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-07-10 09:35:46,091 - DEBUG - httpcore.connection - _trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1167a9030>
2025-07-10 09:35:46,091 - DEBUG - httpcore.connection - _trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x1161e7740> server_hostname='api.openai.com' timeout=5.0
2025-07-10 09:35:51,093 - DEBUG - httpcore.connection - _trace:47 - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:990: The handshake operation timed out'))
2025-07-10 09:35:51,094 - DEBUG - openai._base_client - _base_client:978 - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/openai/_base_client.py", line 972, in request
    response = self._client.send(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:990: The handshake operation timed out
2025-07-10 09:35:51,096 - DEBUG - openai._base_client - _base_client:989 - Raising timeout error
2025-07-10 09:35:51,857 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:35:51,862 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:35:51,862 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:35:51,866 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:35:51,872 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:35:51,873 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:35:51,873 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:35:51,875 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:35:51,882 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:35:51,883 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:35:51,883 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): 'NoneType' object has no attribute 'decompose_task'
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
AttributeError: 'NoneType' object has no attribute 'decompose_task'
2025-07-10 09:35:51,885 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:37:14,099 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:37:14,100 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:37:14,627 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:37:14,627 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:37:14,630 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:37:14,631 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:37:14,631 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:37:14,640 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:37:14,640 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:37:14,640 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:37:14,646 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:37:14,646 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:37:14,653 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:37:14,653 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:37:14,657 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:37:14,657 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:37:14,786 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:37:14,789 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:37:14,791 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:37:14,791 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:37:14,895 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:37:14,895 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:37:14,895 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:37:14,907 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:37:14,907 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:37:15,008 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:37:15,008 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:37:15,008 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:37:15,010 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:37:15,010 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:37:15,110 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:37:15,110 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:37:15,111 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:37:15,112 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:37:15,112 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:37:15,218 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:37:15,218 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:37:15,218 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:37:15,220 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:37:15,220 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:37:15,321 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:37:15,321 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:37:15,322 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:15,325 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:37:15,326 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:37:15,426 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:37:16,420 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:37:16,423 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:37:16,432 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:37:16,435 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:37:16,436 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:37:16,440 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:37:16,440 - INFO - root - core:35 - 开始分解任务: Test Goal
2025-07-10 09:37:16,440 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Test Goal"

请开始分解任务并生成JSON。

2025-07-10 09:37:16,545 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:37:16,546 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:37:16,546 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,547 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,548 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:37:16,571 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:37:16,573 - INFO - root - core:35 - 开始分解任务: Invalid Goal
2025-07-10 09:37:16,573 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Invalid Goal"

请开始分解任务并生成JSON。

2025-07-10 09:37:16,674 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:37:16,685 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:37:16,690 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,690 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,692 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:37:16,730 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:37:16,730 - INFO - root - core:35 - 开始分解任务: Error Goal
2025-07-10 09:37:16,730 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Error Goal"

请开始分解任务并生成JSON。

2025-07-10 09:37:16,836 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:37:16,838 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:37:16,840 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,840 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:37:16,845 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:38:39,217 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:38:39,218 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:38:39,351 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:38:39,351 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:38:39,356 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:38:39,356 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:38:39,356 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:38:39,368 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:38:39,368 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:38:39,369 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:38:39,376 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:38:39,376 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:38:39,387 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:38:39,387 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:38:39,394 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:38:39,394 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:38:39,496 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:38:39,500 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:38:39,546 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:38:39,548 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:38:39,654 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:38:39,655 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:38:39,657 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:38:39,787 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:38:39,787 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:38:39,906 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:38:39,907 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:38:39,907 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:38:39,909 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:38:39,910 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:38:40,016 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:38:40,016 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:38:40,016 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:38:40,021 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:38:40,021 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:38:40,126 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:38:40,126 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:38:40,127 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:38:40,129 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:38:40,129 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:38:40,230 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:38:40,230 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:38:40,231 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:40,234 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:38:40,235 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:38:40,340 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:38:41,328 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:38:41,331 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:38:41,452 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:38:41,459 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:38:41,460 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:38:41,503 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:38:41,504 - INFO - root - core:35 - 开始分解任务: Test Goal
2025-07-10 09:38:41,504 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Test Goal"

请开始分解任务并生成JSON。

2025-07-10 09:38:41,607 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:38:41,608 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:38:41,608 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,608 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,609 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:38:41,616 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:38:41,617 - INFO - root - core:35 - 开始分解任务: Invalid Goal
2025-07-10 09:38:41,617 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Invalid Goal"

请开始分解任务并生成JSON。

2025-07-10 09:38:41,722 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:38:41,722 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:38:41,722 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,723 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,723 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:38:41,731 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:38:41,731 - INFO - root - core:35 - 开始分解任务: Error Goal
2025-07-10 09:38:41,731 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Error Goal"

请开始分解任务并生成JSON。

2025-07-10 09:38:41,833 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:38:41,833 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:38:41,833 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,834 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:38:41,834 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:39:43,024 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:39:43,025 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:39:43,260 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:39:43,261 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:39:43,268 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:39:43,268 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:39:43,280 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:39:43,367 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:39:43,371 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:39:43,372 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:39:43,379 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:39:43,379 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:39:43,386 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:39:43,386 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:39:43,391 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:39:43,391 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:39:43,567 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:39:43,569 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:39:43,575 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:39:43,575 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:39:43,676 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:39:43,677 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:39:43,677 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:39:43,694 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:39:43,695 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:39:43,801 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:39:43,802 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:39:43,802 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:39:43,807 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:39:43,813 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:39:43,920 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:39:43,921 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:39:43,921 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:39:43,922 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:39:43,922 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:39:44,027 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:39:44,028 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:39:44,028 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:39:44,029 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:39:44,030 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:39:44,133 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:39:44,134 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:39:44,135 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:44,139 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:39:44,140 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:39:44,241 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:39:45,186 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:39:45,191 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:39:45,201 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:39:45,204 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:39:45,204 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:39:45,209 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:39:45,209 - INFO - root - core:35 - 开始分解任务: Test Goal
2025-07-10 09:39:45,210 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Test Goal"

请开始分解任务并生成JSON。

2025-07-10 09:39:45,332 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:39:45,333 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:39:45,340 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,340 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,343 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:39:45,355 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:39:45,355 - INFO - root - core:35 - 开始分解任务: Invalid Goal
2025-07-10 09:39:45,355 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Invalid Goal"

请开始分解任务并生成JSON。

2025-07-10 09:39:45,458 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:39:45,459 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:39:45,459 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,460 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,460 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:39:45,470 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:39:45,470 - INFO - root - core:35 - 开始分解任务: Error Goal
2025-07-10 09:39:45,471 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "Error Goal"

请开始分解任务并生成JSON。

2025-07-10 09:39:45,571 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "\u6b65\u9aa4A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "\u6b65\u9aa4B", "dependencies": ["stepA"]}]}
2025-07-10 09:39:45,571 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:39:45,572 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,572 - WARNING - root - server:95 - 分解请求失败 (客户端错误): 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:39:45,572 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:40:28,742 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:40:28,742 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:29,154 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:40:29,154 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:29,157 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:40:29,157 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:29,157 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:40:29,169 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:40:29,169 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:29,169 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:40:29,177 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:40:29,178 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:40:29,183 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:40:29,184 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:40:29,188 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:40:29,188 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,289 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:40:29,290 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:40:29,293 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:40:29,293 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,397 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:40:29,397 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:40:29,397 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:40:29,413 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:40:29,413 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,518 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:40:29,518 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:40:29,518 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:40:29,520 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:40:29,520 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,623 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:40:29,624 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:40:29,624 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:40:29,626 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:40:29,626 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,728 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:40:29,729 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:40:29,729 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:40:29,730 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:40:29,730 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,831 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:40:29,832 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:40:29,832 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:40:29,833 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:40:29,834 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:40:29,936 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:40:30,881 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:40:30,886 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:40:30,896 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:40:30,898 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:40:30,898 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:40:30,903 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:40:30,903 - INFO - root - server:88 - 任务分解成功，返回结果。
2025-07-10 09:40:30,906 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 200 OK"
2025-07-10 09:40:30,909 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:40:30,910 - WARNING - root - server:95 - 分解请求失败 (客户端错误): Invalid input
2025-07-10 09:40:30,910 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:40:30,912 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:40:30,912 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): Internal Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Internal Error
2025-07-10 09:40:30,913 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:40:58,392 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:40:58,392 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:58,520 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:40:58,520 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:58,524 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:40:58,524 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:58,524 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:40:58,532 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:40:58,532 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:40:58,533 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:40:58,541 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:40:58,541 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:40:58,546 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:40:58,547 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:40:58,553 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:40:58,553 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:40:58,679 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:40:58,684 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:40:58,686 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:40:58,706 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:40:58,809 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:40:58,809 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:40:58,810 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:40:58,811 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:40:58,811 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:40:58,916 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:40:58,916 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:40:58,916 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:40:58,918 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:40:58,918 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:40:59,019 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:40:59,019 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:40:59,019 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:40:59,021 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:40:59,021 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:40:59,125 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:40:59,125 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:40:59,125 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:40:59,128 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:40:59,128 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:40:59,233 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:40:59,234 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:40:59,235 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:40:59,236 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:40:59,236 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:40:59,340 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:41:00,321 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:41:00,326 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:41:00,342 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:41:00,345 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:41:00,346 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:41:00,350 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:41:00,350 - INFO - root - server:88 - 任务分解成功，返回结果。
2025-07-10 09:41:00,353 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 200 OK"
2025-07-10 09:41:00,357 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:41:00,358 - WARNING - root - server:95 - 分解请求失败 (客户端错误): Invalid input
2025-07-10 09:41:00,358 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:41:00,361 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:41:00,361 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): Internal Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Internal Error
2025-07-10 09:41:00,362 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:41:54,541 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:41:54,542 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:41:54,803 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:41:54,803 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:41:54,807 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:41:54,808 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:41:54,808 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:41:54,819 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:41:54,819 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:41:54,819 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:41:54,826 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:41:54,827 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:41:54,835 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:41:54,835 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:41:54,839 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:41:54,840 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:41:54,943 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:41:54,949 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:41:54,998 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:41:54,998 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,099 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:41:55,099 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:41:55,099 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:41:55,101 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:41:55,101 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,203 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:41:55,203 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:41:55,204 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:41:55,205 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:41:55,205 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,310 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:41:55,310 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:41:55,311 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:41:55,312 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:41:55,312 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,417 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:41:55,417 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:41:55,418 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:41:55,419 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:41:55,419 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,521 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:41:55,522 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:41:55,522 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:41:55,523 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:41:55,524 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:41:55,625 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:41:56,362 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:41:56,365 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:41:56,376 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:41:56,379 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:41:56,379 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:41:56,382 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:41:56,382 - INFO - root - server:88 - 任务分解成功，返回结果。
2025-07-10 09:41:56,386 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 200 OK"
2025-07-10 09:41:56,388 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:41:56,389 - WARNING - root - server:95 - 分解请求失败 (客户端错误): Invalid input
2025-07-10 09:41:56,389 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:41:56,391 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:41:56,392 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): Internal Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Internal Error
2025-07-10 09:41:56,392 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:43:00,083 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:43:00,086 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:00,092 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:43:00,092 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:00,097 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:43:00,097 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:00,098 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:43:00,107 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:43:00,108 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:00,112 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:43:00,447 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:43:00,447 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:43:00,452 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:43:00,454 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:43:00,457 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:43:00,457 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:43:00,557 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:43:00,558 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:43:00,561 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:43:00,561 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:43:00,665 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:43:00,666 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:43:00,666 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:43:00,668 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:43:00,668 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:43:00,773 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:43:00,773 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:43:00,773 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:43:00,775 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:43:00,775 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:43:00,880 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:43:00,881 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:43:00,881 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:43:00,882 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:43:00,883 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:43:00,985 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:43:00,986 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:43:00,986 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:43:00,987 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:43:00,988 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:43:01,093 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:43:01,093 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:43:01,094 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:43:01,095 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:43:01,095 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:43:01,198 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:43:01,967 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:43:01,972 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:43:02,002 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:43:02,004 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:43:02,004 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:43:02,010 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:43:02,011 - INFO - root - server:88 - 任务分解成功，返回结果。
2025-07-10 09:43:02,016 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 200 OK"
2025-07-10 09:43:02,021 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:43:02,024 - WARNING - root - server:95 - 分解请求失败 (客户端错误): Invalid input
2025-07-10 09:43:02,024 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:43:02,031 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:43:02,032 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): Internal Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Internal Error
2025-07-10 09:43:02,033 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
2025-07-10 09:43:51,800 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:43:51,801 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:51,805 - INFO - root - cli:30 - CLI: 开始分解目标: Test Goal
2025-07-10 09:43:51,806 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:51,808 - INFO - root - cli:30 - CLI: 开始分解目标: Error Goal
2025-07-10 09:43:51,808 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:51,808 - CRITICAL - root - cli:93 - CLI: 发生意外错误: LLM API Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/cli.py", line 46, in decompose
    graph, steps_details = decomposer.decompose_task(goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
RuntimeError: LLM API Error
2025-07-10 09:43:51,813 - INFO - root - cli:30 - CLI: 开始分解目标: Invalid Goal
2025-07-10 09:43:51,813 - INFO - root - cli:36 - CLI: 使用 Mock LLM 客户端。
2025-07-10 09:43:51,814 - ERROR - root - cli:87 - CLI: 任务分解失败 (输入或逻辑错误): Invalid input
2025-07-10 09:43:51,818 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:43:51,818 - INFO - root - cli:43 - CLI: 使用 OpenAI LLM 客户端。
2025-07-10 09:43:51,820 - INFO - root - cli:30 - CLI: 开始分解目标: OpenAI Goal
2025-07-10 09:43:51,820 - ERROR - root - cli:90 - CLI: 命令行参数错误: OpenAI API Key未提供。请使用 --api-key 选项或设置 OPENAI_API_KEY 环境变量。
2025-07-10 09:43:51,821 - INFO - root - core:35 - 开始分解任务: 分解一个简单的任务
2025-07-10 09:43:51,822 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "分解一个简单的任务"

请开始分解任务并生成JSON。

2025-07-10 09:43:51,927 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1", "description": "\u7b2c\u4e00\u6b65", "dependencies": []}, {"id": "step2", "description": "\u7b2c\u4e8c\u6b65", "dependencies": ["step1"]}]}
2025-07-10 09:43:51,931 - INFO - root - core:95 - 任务分解成功，生成了包含 2 个节点和 1 条边的DAG。
2025-07-10 09:43:51,938 - INFO - root - core:35 - 开始分解任务: 测试无效JSON
2025-07-10 09:43:51,940 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试无效JSON"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,051 - DEBUG - root - core:43 - LLM原始响应: "\u65e0\u6548\u7684JSON"
2025-07-10 09:43:52,052 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:43:52,053 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:43:52,055 - INFO - root - core:35 - 开始分解任务: 测试缺少steps键
2025-07-10 09:43:52,056 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少steps键"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,159 - DEBUG - root - core:43 - LLM原始响应: {"data": "some_data"}
2025-07-10 09:43:52,159 - ERROR - root - core:53 - LLM响应缺少'steps'键或格式不正确。
2025-07-10 09:43:52,159 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应格式不符合预期，缺少'steps'键。
2025-07-10 09:43:52,161 - INFO - root - core:35 - 开始分解任务: 测试steps不是列表
2025-07-10 09:43:52,161 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试steps不是列表"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,266 - DEBUG - root - core:43 - LLM原始响应: {"steps": "\u4e0d\u662f\u5217\u8868"}
2025-07-10 09:43:52,267 - ERROR - root - core:58 - LLM响应中的'steps'不是列表。
2025-07-10 09:43:52,267 - ERROR - root - core:99 - 任务分解业务逻辑错误: LLM响应中的'steps'不是列表。
2025-07-10 09:43:52,268 - INFO - root - core:35 - 开始分解任务: 测试缺少id或description
2025-07-10 09:43:52,268 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试缺少id或description"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,373 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "step1"}]}
2025-07-10 09:43:52,374 - ERROR - root - core:72 - 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:43:52,374 - ERROR - root - core:99 - 任务分解业务逻辑错误: 步骤数据缺少'id'或'description': {'id': 'step1'}
2025-07-10 09:43:52,375 - INFO - root - core:35 - 开始分解任务: 测试循环依赖
2025-07-10 09:43:52,376 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试循环依赖"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,477 - DEBUG - root - core:43 - LLM原始响应: {"steps": [{"id": "stepA", "description": "A", "dependencies": ["stepB"]}, {"id": "stepB", "description": "B", "dependencies": ["stepA"]}]}
2025-07-10 09:43:52,477 - WARNING - root - core:87 - 步骤 'stepA' 依赖于不存在的步骤 'stepB'。
2025-07-10 09:43:52,478 - ERROR - root - core:99 - 任务分解业务逻辑错误: 图验证失败: 检测到循环依赖: [('stepA', 'stepB'), ('stepB', 'stepA')]
2025-07-10 09:43:52,480 - INFO - root - core:35 - 开始分解任务: 测试LLM客户端错误
2025-07-10 09:43:52,480 - DEBUG - root - core:39 - LLM提示: 
你是一个高级任务分解助手。你的任务是将一个高层级的用户目标分解成一系列清晰、可执行的原子步骤。
每个步骤都必须有一个唯一的ID，一个描述，以及一个可选的依赖步骤列表和可选的机器指令列表。
请确保所有步骤形成一个有向无环图（DAG），即没有循环依赖。

输出必须严格遵循以下JSON格式：
{
  "steps": [
    {
      "id": "string", // 唯一的步骤标识符，例如 "step1", "task_setup", "data_processing"
      "description": "string", // 对该步骤的简短描述，例如 "初始化项目", "收集用户输入"
      "dependencies": ["string"], // 可选，该步骤依赖的其他步骤的ID列表。如果无依赖，则为空列表。
      "instructions": ["string"] // 可选，该步骤的详细机器可执行指令列表，例如命令行命令、代码片段等。
    }
  ]
}

请注意以下几点：
1.  `id` 必须是字符串，且在所有步骤中唯一。
2.  `description` 必须是字符串，简洁明了。
3.  `dependencies` 必须是一个字符串列表，其中每个字符串都是其他步骤的 `id`。如果一个步骤没有依赖，`dependencies` 字段应为空列表 `[]`。
4.  `instructions` 必须是一个字符串列表，包含该步骤的具体执行指令。如果无指令，则为空列表 `[]`。
5.  确保所有 `dependencies` 中引用的 `id` 都存在于 `steps` 列表中。
6.  分解的粒度应适中，每个步骤应是相对独立的、可完成的单元。
7.  不要包含任何额外的文本或解释，只返回纯JSON。

用户目标: "测试LLM客户端错误"

请开始分解任务并生成JSON。

2025-07-10 09:43:52,583 - CRITICAL - root - core:102 - 任务分解过程中发生意外错误: Mock LLM 模拟错误。
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/core.py", line 42, in decompose_task
    llm_response_str = self.llm_client.generate(prompt)
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/llm_integration/mock_clients.py", line 20, in generate
    raise RuntimeError("Mock LLM 模拟错误。")
RuntimeError: Mock LLM 模拟错误。
2025-07-10 09:43:53,352 - ERROR - root - test_log:31 - This is an error message.
2025-07-10 09:43:53,356 - DEBUG - root - test_log:48 - 这是一个测试日志消息。
2025-07-10 09:43:53,367 - DEBUG - asyncio - selector_events:54 - Using selector: KqueueSelector
2025-07-10 09:43:53,369 - INFO - root - server:64 - 开发环境启动...
2025-07-10 09:43:53,370 - INFO - root - server:76 - TaskDecomposer 初始化完成。
2025-07-10 09:43:53,373 - INFO - root - server:80 - 接收到分解请求，目标: Test Goal
2025-07-10 09:43:53,373 - INFO - root - server:88 - 任务分解成功，返回结果。
2025-07-10 09:43:53,376 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 200 OK"
2025-07-10 09:43:53,379 - INFO - root - server:80 - 接收到分解请求，目标: Invalid Goal
2025-07-10 09:43:53,379 - WARNING - root - server:95 - 分解请求失败 (客户端错误): Invalid input
2025-07-10 09:43:53,380 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 400 Bad Request"
2025-07-10 09:43:53,382 - INFO - root - server:80 - 接收到分解请求，目标: Error Goal
2025-07-10 09:43:53,382 - ERROR - root - server:98 - 分解请求失败 (服务器内部错误): Internal Error
Traceback (most recent call last):
  File "/Users/zhaoxuefeng/GitHub/primalstep/src/primalstep/server.py", line 82, in decompose_task_endpoint
    graph, steps_details = task_decomposer.decompose_task(request.goal)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1114, in __call__
    return self._mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1118, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
  File "/Users/zhaoxuefeng/opt/miniconda3/envs/baseProject/lib/python3.10/unittest/mock.py", line 1173, in _execute_mock_call
    raise effect
Exception: Internal Error
2025-07-10 09:43:53,382 - INFO - httpx - _client:1025 - HTTP Request: POST http://testserver/decompose "HTTP/1.1 500 Internal Server Error"
